{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Processing\n",
    "\n",
    "##### 1.1 X-y split.\n",
    "\n",
    "In order to do the X-y split, we need to figure out the inputs and outputs of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Find more information about the dataset\n",
    "df = pd.read_csv('files_for_lab/csv_files/marketing_customer_analysis.csv')\n",
    "print(df.info())\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "# Run the transformations from the previous lab\n",
    "\n",
    "# 1. Standardize column names\n",
    "df.rename(columns = {'EmploymentStatus': 'Employment Status'}, inplace = True)\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# 2. Remove columns that are highly correlated to each other\n",
    "df.drop(['policy', 'vehicle size'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assume that the `total claim amount` is the output we're looking to predict, as for an insurance policy company it would be relevant to know which customer type is more likely to make claims - so that they can perhaps change the insurance policy pricing for customers that would be considered \"high-risk\", i.e. more likely to make claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(df['total claim amount'])\n",
    "X = df.drop('total claim amount', axis=1)\n",
    "\n",
    "# Check that the operations ran correctly\n",
    "print(y.columns)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2. Normalize (numerical).\n",
    "\n",
    "We need to separate the numerical columns in X from the categorical columns so we can normalize the data at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X.select_dtypes(include=np.number)\n",
    "\n",
    "# Check that we have selected the correct data\n",
    "print(X_num.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can normalize the data using `MinMaxScaler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the minimum and maximum for each column of the dataframe:\n",
    "transformer = MinMaxScaler().fit(X_num) \n",
    "\n",
    "# Find out what the transformer is:\n",
    "print(type(transformer))\n",
    "\n",
    "# Show the maximum across all columns (mainly to see what the info in the transformer):\n",
    "print(transformer.data_max_)\n",
    "\n",
    "# Normalize the data (or transform):\n",
    "x_minmax = transformer.transform(X_num)\n",
    "print(type(x_minmax))\n",
    "print(x_minmax.shape)\n",
    "\n",
    "# Transform the numpy array into the normalized dataframe \n",
    "X_num_norm = pd.DataFrame(x_minmax, columns=X_num.columns)\n",
    "print(X_num_norm.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3. One Hot/Label Encoding (categorical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the categorical values\n",
    "X_cat = X.select_dtypes(include=np.object)\n",
    "X_cat.drop('customer', axis=1, inplace=True)\n",
    "\n",
    "# Check that we selected the right data\n",
    "print(X_cat.info())\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='error', drop='first')\n",
    "encoder.fit(X_cat)\n",
    "print(type(encoder.categories_))\n",
    "print(encoder.get_feature_names_out())\n",
    "\n",
    "# Extract the encoded array from the encoder\n",
    "encoded = encoder.transform(X_cat).toarray()\n",
    "\n",
    "# Transform the numpy array to a Pandas dataframe\n",
    "cat_encoded = pd.DataFrame(encoded)\n",
    "\n",
    "# Add column names to the dataframe\n",
    "cat_encoded.columns = encoder.get_feature_names_out()\n",
    "\n",
    "# Check the encoded dataframe\n",
    "print(cat_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5. Concat DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_num_norm, cat_encoded], axis=1)\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Linear Regression\n",
    "\n",
    "##### 2.1. Train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Apply linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get the predictions before describing the model:\n",
    "predictions  = model.predict(X_test)\n",
    "\n",
    "# Learn more about the predictions:\n",
    "print(predictions.shape)\n",
    "print(type(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model Validation\n",
    "\n",
    "Description: R2, MSE, RMSE, MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, predictions)\n",
    "RMSE = mean_squared_error(y_test, predictions, squared=False)\n",
    "MSE = mean_squared_error(y_test, predictions)\n",
    "MAE = np.mean(abs(y_test.to_numpy() - predictions))\n",
    "\n",
    "print(\"r2 = \", r2)\n",
    "print(\"RMSE = \", RMSE)\n",
    "print(\"MSE = \", MSE)\n",
    "print(\"MAE = \", MAE)\n",
    "\n",
    "median_total_claim = np.median(y_test.to_numpy())\n",
    "print(\"Median Total Claim = \", median_total_claim)\n",
    "\n",
    "print(RMSE * 100 / median_total_claim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The r2 score is relatively high, which means that the model is decent at predicting the total claim value. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
